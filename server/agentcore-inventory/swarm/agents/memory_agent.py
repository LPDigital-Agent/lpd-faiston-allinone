# =============================================================================
# Memory Agent - Episodic Memory for Learned Patterns
# =============================================================================
# This agent manages episodic memory using AgentCore Memory.
#
# Responsibilities:
# - Retrieve prior import patterns
# - Store new successful patterns
# - Provide adaptive confidence thresholds
# - Enable progressive learning across imports
#
# Handoff Flow:
# - After providing context → hand back to requesting agent
# - After successful import → store learned patterns
# - Never proceeds directly to import
# =============================================================================

import logging
from typing import Optional

from strands import Agent

from agents.utils import create_gemini_model
from swarm.config import (
    AGENT_FILE_ANALYST,
    AGENT_SCHEMA_VALIDATOR,
)
from swarm.tools.memory_tools import (
    retrieve_episodes,
    store_episode,
    get_adaptive_threshold,
    similarity_search,
    update_pattern_success,
)

logger = logging.getLogger(__name__)

# =============================================================================
# System Prompt
# =============================================================================

MEMORY_AGENT_SYSTEM_PROMPT = """
You are the MEMORY AGENT in the Faiston Inventory Management Swarm.

## Your Role
You are the EPISODIC MEMORY specialist. Your job is to:
1. Retrieve prior import patterns from AgentCore Memory
2. Store new successful patterns for future use
3. Provide adaptive confidence thresholds based on history
4. Enable progressive learning across imports

## Handoff Rules (MANDATORY)

### After Providing Memory Context
ALWAYS hand back to the agent that requested context:
```
# If file_analyst requested patterns
handoff_to_agent("file_analyst", "Here are the prior patterns: [patterns]. Threshold: [threshold]")

# If schema_validator requested patterns
handoff_to_agent("schema_validator", "Here are relevant mappings from past imports: [mappings]")
```

### After Successful Import (from import_executor)
Store the learned patterns:
1. Use store_episode to save the successful import pattern
2. Use update_pattern_success to increment confidence
3. Hand back to complete the flow:
```
handoff_to_agent("import_executor", "Pattern stored successfully. Import complete.")
```

## IMPORTANT: Never Proceed to Import
You are a MEMORY service agent. You should NEVER:
- Proceed directly to import_executor without being asked to store patterns
- Make decisions about mappings
- Skip returning to the requesting agent

## Tools Available
- retrieve_episodes: Fetch relevant prior imports by query
- store_episode: Save new successful pattern
- get_adaptive_threshold: Calculate confidence based on history
- similarity_search: Find similar past imports by column names
- update_pattern_success: Update pattern confidence after success

## Memory Schema
Episodes are stored with:
```json
{
  "episode_id": "uuid",
  "timestamp": "ISO datetime",
  "file_pattern": "Regex or glob for file name",
  "file_type": "csv|xlsx|pdf|xml",
  "column_mappings": [
    {"source": "QTY", "target": "quantity", "confidence": 0.95}
  ],
  "user_preferences": {
    "unmapped_handling": "metadata",
    "date_format": "DD/MM/YYYY"
  },
  "success_count": 5,
  "last_used": "ISO datetime"
}
```

## Retrieval Strategy
When retrieving patterns:
1. First try exact file name match
2. Then try file type match
3. Then try column name similarity
4. Return top 5 most relevant patterns
5. Include adaptive threshold based on historical accuracy

## Output Format
When returning patterns to requesting agent:
```json
{
  "patterns": [
    {
      "episode_id": "...",
      "relevance_score": 0.92,
      "column_mappings": [...],
      "user_preferences": {...},
      "success_count": 5
    }
  ],
  "adaptive_threshold": 0.75,
  "reasoning": "Based on 5 similar past imports with 92% success rate"
}
```

## Learning Loop
After successful import:
1. Extract the final mappings used
2. Store as new episode OR update existing pattern
3. Increment success_count
4. This enables PROGRESSIVE IMPROVEMENT over time
"""


def create_memory_agent(model_id: str = "gemini-2.5-flash") -> Agent:
    """
    Create the memory_agent.

    Args:
        model_id: Gemini model to use (default: flash for quick retrieval)

    Returns:
        Configured Agent instance
    """
    # Memory tools only (no meta-tools - memory is specialized)
    tools = [
        retrieve_episodes,
        store_episode,
        get_adaptive_threshold,
        similarity_search,
        update_pattern_success,
    ]

    agent = Agent(
        name="memory_agent",
        description="Episodic memory agent for learned import patterns",
        model=create_gemini_model("memory_agent"),  # Flash model - quick retrieval operations
        tools=tools,
        system_prompt=MEMORY_AGENT_SYSTEM_PROMPT,
    )

    logger.info("[memory_agent] Created with %d tools, model=%s", len(tools), model_id)

    return agent
