# =============================================================================
# Response Contract Tests - BUG-015 Fix
# =============================================================================
# Tests to verify that the Swarm response extraction follows the official
# Strands pattern and returns the correct NexoAnalyzeFileResponse format.
#
# Official Strands Pattern:
# - result.results["agent_name"].result contains agent output
# - Reference: https://strandsagents.com/latest/
# =============================================================================

import json
import pytest
from unittest.mock import Mock, MagicMock, patch


class TestSwarmResponseExtraction:
    """
    Test that Swarm results are correctly processed using official Strands patterns.

    The fix for BUG-015 uses result.results["file_analyst"].result which is the
    OFFICIAL Strands pattern for accessing individual agent results.
    """

    def test_extracts_analysis_from_results_dict(self):
        """
        Should extract tool output from result.results["file_analyst"].result.

        This is the PRIMARY extraction method per official Strands documentation:
        https://github.com/strands-agents/docs/blob/main/docs/user-guide/concepts/multi-agent/swarm.md
        """
        # Import the function to test (will be created)
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        # Create mock SwarmResult with official structure
        mock_agent_result = Mock()
        mock_agent_result.result = {
            "success": True,
            "analysis": {
                "sheet_count": 1,
                "total_rows": 150,
                "sheets": [
                    {
                        "name": "Sheet1",
                        "row_count": 150,
                        "column_count": 5,
                        "columns": [{"name": "PART_NUMBER", "confidence": 0.95}],
                        "confidence": 0.92,
                    }
                ],
                "recommended_strategy": "auto_import",
            },
            "overall_confidence": 0.92,
        }

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        # Execute
        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        # Verify
        assert result is not None
        assert "analysis" in result
        assert "sheets" in result["analysis"]
        assert len(result["analysis"]["sheets"]) == 1
        assert result["analysis"]["sheets"][0]["name"] == "Sheet1"

    def test_extracts_analysis_from_string_result(self):
        """
        Should parse JSON string from result.results["agent"].result.

        Sometimes agents return JSON as string instead of dict.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        # Agent returns JSON string
        mock_agent_result = Mock()
        mock_agent_result.result = json.dumps(
            {
                "success": True,
                "analysis": {
                    "sheets": [{"name": "Data", "row_count": 100}],
                    "sheet_count": 1,
                },
            }
        )

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "Data"

    def test_returns_none_when_no_results(self):
        """Should return None when result.results is empty or missing."""
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        # No results attribute - use spec to explicitly exclude attributes
        mock_result = Mock(spec=["message"])  # Only has message, no results/entry_point
        mock_result.message = "Some text"
        result = _extract_tool_output_from_swarm_result(
            mock_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )
        assert result is None

        # Empty results dict and no entry_point with messages
        mock_result2 = Mock()
        mock_result2.results = {}
        # Properly mock entry_point to avoid iteration error
        mock_result2.entry_point = Mock()
        mock_result2.entry_point.messages = []  # Empty messages list
        result2 = _extract_tool_output_from_swarm_result(
            mock_result2, agent_name="file_analyst", tool_name="unified_analyze_file"
        )
        assert result2 is None

    def test_extracts_from_entry_point_messages_fallback(self):
        """
        Should extract from entry_point.messages if results not available.

        This is the fallback method using agent message history.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        # Mock entry_point with messages containing tool_result
        mock_entry_point = Mock()
        mock_entry_point.messages = [
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": "tool_123",
                        "content": json.dumps(
                            {
                                "success": True,
                                "analysis": {
                                    "sheets": [{"name": "Inventory", "row_count": 50}],
                                    "sheet_count": 1,
                                },
                            }
                        ),
                    }
                ],
            }
        ]

        mock_result = Mock()
        mock_result.results = {}  # Empty results
        mock_result.entry_point = mock_entry_point

        result = _extract_tool_output_from_swarm_result(
            mock_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "Inventory"


class TestProcessSwarmResult:
    """
    Test the updated _process_swarm_result function.

    This function should use the official Strands pattern as PRIORITY 1,
    with fallbacks for JSON parsing and regex extraction.
    """

    def test_process_swarm_result_uses_results_first(self):
        """
        Priority 1: Should extract from result.results before trying message.

        This ensures we get the RAW tool output, not LLM-summarized text.
        """
        from swarm.response_utils import _process_swarm_result

        # Create mock with both results and message
        mock_agent_result = Mock()
        mock_agent_result.result = {
            "success": True,
            "analysis": {
                "sheets": [{"name": "FromResults", "row_count": 100}],
                "sheet_count": 1,
            },
            "overall_confidence": 0.95,
        }

        mock_result = Mock()
        mock_result.results = {"file_analyst": mock_agent_result}
        mock_result.message = "I analyzed the file..."  # LLM summary (should be ignored)
        mock_result.node_history = []

        session = {"context": {}}

        response = _process_swarm_result(mock_result, session)

        # Should use results, not message
        assert "analysis" in response
        assert response["analysis"]["sheets"][0]["name"] == "FromResults"
        assert "I analyzed" not in str(response)

    def test_process_swarm_result_falls_back_to_message_json(self):
        """
        Priority 2: Should parse message as JSON if results unavailable.
        """
        from swarm.response_utils import _process_swarm_result

        mock_result = Mock()
        mock_result.results = {}
        # Properly mock entry_point with empty messages
        mock_result.entry_point = Mock()
        mock_result.entry_point.messages = []
        mock_result.message = json.dumps(
            {
                "success": True,
                "analysis": {
                    "sheets": [{"name": "FromMessage", "row_count": 50}],
                    "sheet_count": 1,
                },
            }
        )
        mock_result.node_history = []

        session = {"context": {}}

        response = _process_swarm_result(mock_result, session)

        assert "analysis" in response
        assert response["analysis"]["sheets"][0]["name"] == "FromMessage"

    def test_process_swarm_result_extracts_json_from_text(self):
        """
        Priority 3: Should extract JSON from natural language message.

        When LLM wraps JSON in text like "Here is the analysis: {...}"
        """
        from swarm.response_utils import _process_swarm_result

        mock_result = Mock()
        mock_result.results = {}
        # Properly mock entry_point with empty messages
        mock_result.entry_point = Mock()
        mock_result.entry_point.messages = []
        mock_result.message = (
            'I analyzed the file successfully. Here is the result: '
            '{"success": true, "analysis": {"sheets": [{"name": "Extracted", "row_count": 75}], "sheet_count": 1}}'
        )
        mock_result.node_history = []

        session = {"context": {}}

        response = _process_swarm_result(mock_result, session)

        assert "analysis" in response
        assert response["analysis"]["sheets"][0]["name"] == "Extracted"

    def test_process_swarm_result_stores_raw_message_as_fallback(self):
        """
        Priority 4: Should store raw message if no JSON found.
        """
        from swarm.response_utils import _process_swarm_result

        mock_result = Mock()
        mock_result.results = {}
        # Properly mock entry_point with empty messages
        mock_result.entry_point = Mock()
        mock_result.entry_point.messages = []
        mock_result.message = "I could not analyze the file due to an error."
        mock_result.node_history = []

        session = {"context": {}}

        response = _process_swarm_result(mock_result, session)

        assert "message" in response
        assert "I could not analyze" in response["message"]

    def test_process_swarm_result_updates_session_context(self):
        """Should update session context with analysis data."""
        from swarm.response_utils import _process_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = {
            "success": True,
            "analysis": {"sheets": [], "sheet_count": 0},
            "proposed_mappings": [{"file_column": "A", "target_field": "part_number"}],
            "unmapped_columns": ["B", "C"],
        }

        mock_result = Mock()
        mock_result.results = {"file_analyst": mock_agent_result}
        mock_result.node_history = []

        session = {"context": {}}

        _process_swarm_result(mock_result, session)

        assert "analysis" in session["context"]
        assert "proposed_mappings" in session["context"]
        assert "unmapped_columns" in session["context"]


class TestNexoAnalyzeFileResponseContract:
    """
    Test that analyze_file tool returns the correct NexoAnalyzeFileResponse format.

    This verifies the TypeScript contract is satisfied:
    - analysis.sheets must be an array
    - overall_confidence must exist
    - column_mappings must be an array
    """

    @pytest.mark.asyncio
    async def test_returns_nested_analysis_object(self):
        """
        Analysis must be nested under 'analysis' key.

        TypeScript expects: response.analysis.sheets
        """
        with patch("tools.gemini_text_analyzer.analyze_file_with_gemini") as mock_gemini:
            mock_gemini.return_value = {
                "success": True,
                "filename": "test.csv",
                "file_type": "csv",
                "columns": [
                    {
                        "source_name": "PART_NUMBER",
                        "suggested_mapping": "part_number",
                        "mapping_confidence": 0.95,
                        "data_type": "string",
                        "sample_values": ["C9200-24P"],
                    }
                ],
                "row_count": 100,
                "column_count": 1,
                "analysis_confidence": 0.92,
                "recommended_action": "auto_import",
                "hil_questions": [],
                "unmapped_columns": [],
                "ready_for_import": True,
                "analysis_round": 1,
            }

            from agents.specialists.nexo_import.tools.analyze_file import analyze_file_tool

            result = await analyze_file_tool(
                s3_key="test/sample.csv",
                filename="sample.csv",
                session_id="test-session",
            )

            # Verify nested analysis structure
            assert "analysis" in result, "Response must have 'analysis' key"
            assert isinstance(result["analysis"], dict), "analysis must be a dict"
            assert "sheets" in result["analysis"], "analysis must have 'sheets'"
            assert isinstance(result["analysis"]["sheets"], list), "sheets must be a list"

    @pytest.mark.asyncio
    async def test_analysis_contains_required_fields(self):
        """
        analysis object must contain sheet_count, total_rows, sheets, recommended_strategy.
        """
        with patch("tools.gemini_text_analyzer.analyze_file_with_gemini") as mock_gemini:
            mock_gemini.return_value = {
                "success": True,
                "filename": "test.csv",
                "file_type": "csv",
                "columns": [],
                "row_count": 50,
                "column_count": 3,
                "analysis_confidence": 0.85,
                "recommended_action": "hil_required",
                "hil_questions": [],
                "unmapped_columns": [],
                "ready_for_import": False,
                "analysis_round": 1,
            }

            from agents.specialists.nexo_import.tools.analyze_file import analyze_file_tool

            result = await analyze_file_tool(s3_key="test/data.csv")

            analysis = result["analysis"]
            assert "sheet_count" in analysis
            assert "total_rows" in analysis
            assert "sheets" in analysis
            assert "recommended_strategy" in analysis

    @pytest.mark.asyncio
    async def test_sheets_have_required_structure(self):
        """
        Each sheet must have: name, row_count, column_count, columns, confidence.
        """
        with patch("tools.gemini_text_analyzer.analyze_file_with_gemini") as mock_gemini:
            mock_gemini.return_value = {
                "success": True,
                "filename": "inventory.csv",
                "file_type": "csv",
                "columns": [
                    {
                        "source_name": "SKU",
                        "suggested_mapping": "sku",
                        "mapping_confidence": 0.99,
                        "data_type": "string",
                        "sample_values": ["ABC-123"],
                    }
                ],
                "row_count": 200,
                "column_count": 1,
                "analysis_confidence": 0.98,
                "recommended_action": "auto_import",
                "hil_questions": [],
                "unmapped_columns": [],
                "ready_for_import": True,
                "analysis_round": 1,
            }

            from agents.specialists.nexo_import.tools.analyze_file import analyze_file_tool

            result = await analyze_file_tool(s3_key="test/inventory.csv")

            sheets = result["analysis"]["sheets"]
            assert len(sheets) >= 1, "Must have at least one sheet"

            sheet = sheets[0]
            assert "name" in sheet
            assert "row_count" in sheet
            assert "column_count" in sheet
            assert "columns" in sheet
            assert "confidence" in sheet

    @pytest.mark.asyncio
    async def test_column_mappings_format(self):
        """
        column_mappings must be array of {file_column, target_field, confidence, reasoning}.
        """
        with patch("tools.gemini_text_analyzer.analyze_file_with_gemini") as mock_gemini:
            mock_gemini.return_value = {
                "success": True,
                "filename": "test.csv",
                "file_type": "csv",
                "columns": [
                    {
                        "source_name": "NUMERO_SERIE",
                        "suggested_mapping": "serial_number",
                        "mapping_confidence": 0.88,
                        "reason": "Portuguese for serial number",
                        "data_type": "string",
                        "sample_values": ["SN001"],
                    }
                ],
                "row_count": 10,
                "column_count": 1,
                "analysis_confidence": 0.88,
                "recommended_action": "auto_import",
                "hil_questions": [],
                "unmapped_columns": [],
                "ready_for_import": True,
                "analysis_round": 1,
            }

            from agents.specialists.nexo_import.tools.analyze_file import analyze_file_tool

            result = await analyze_file_tool(s3_key="test/serials.csv")

            assert "column_mappings" in result
            assert isinstance(result["column_mappings"], list)

            if result["column_mappings"]:
                mapping = result["column_mappings"][0]
                assert "file_column" in mapping
                assert "target_field" in mapping
                assert "confidence" in mapping
                assert "reasoning" in mapping


class TestResponseValidation:
    """
    Test the response validation in _invoke_swarm.

    This ensures we return a proper error instead of undefined when
    the response structure is invalid.
    """

    def test_validates_analysis_exists_for_nexo_analyze_file(self):
        """
        Should return error if analysis is missing for nexo_analyze_file action.
        """
        # This test verifies the validation logic we'll add
        response = {"success": True, "message": "Analysis complete"}  # Missing 'analysis'

        # Validation check
        if not response.get("analysis") or not response.get("analysis", {}).get("sheets"):
            is_valid = False
        else:
            is_valid = True

        assert is_valid is False, "Should detect missing analysis.sheets"

    def test_validates_sheets_is_array(self):
        """
        Should return error if analysis.sheets is not an array.
        """
        response = {
            "success": True,
            "analysis": {
                "sheets": "not an array",  # Invalid!
                "sheet_count": 1,
            },
        }

        sheets = response.get("analysis", {}).get("sheets")
        is_valid = isinstance(sheets, list)

        assert is_valid is False, "Should detect non-array sheets"

    def test_accepts_valid_response(self):
        """
        Should accept valid response with analysis.sheets array.
        """
        response = {
            "success": True,
            "analysis": {
                "sheets": [{"name": "Sheet1", "row_count": 100}],
                "sheet_count": 1,
            },
        }

        sheets = response.get("analysis", {}).get("sheets")
        is_valid = isinstance(sheets, list) and len(sheets) > 0

        assert is_valid is True, "Should accept valid response"


class TestToolResultFormat:
    """
    Test that extraction handles official Strands ToolResult format.

    BUG-015 Fix: Tools now return {"status": "...", "content": [{"json": {...}}]}
    format per official Strands SDK documentation.
    """

    def test_extracts_from_toolresult_json_block(self):
        """
        Should extract from {"status": "success", "content": [{"json": {...}}]}.

        This is the PRIMARY format our unified_analyze_file tool now returns.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = {
            "status": "success",
            "content": [
                {
                    "json": {
                        "success": True,
                        "analysis": {
                            "sheets": [{"name": "Sheet1", "row_count": 100}],
                            "sheet_count": 1,
                        },
                        "overall_confidence": 0.92,
                    }
                }
            ],
        }

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "Sheet1"
        assert result["overall_confidence"] == 0.92

    def test_extracts_from_toolresult_text_block(self):
        """
        Should parse JSON from {"status": "success", "content": [{"text": "..."}]}.

        Fallback path when tool returns text instead of json block.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = {
            "status": "success",
            "content": [
                {
                    "text": json.dumps({
                        "success": True,
                        "analysis": {
                            "sheets": [{"name": "Data", "row_count": 50}],
                            "sheet_count": 1,
                        },
                    })
                }
            ],
        }

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "Data"

    def test_handles_toolresult_with_error_status(self):
        """
        Should still extract content even when status is 'error'.

        Tools may return status='error' but still have useful analysis data.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = {
            "status": "error",
            "content": [
                {
                    "json": {
                        "success": False,
                        "error": "File parsing failed",
                        "analysis": {
                            "sheets": [],
                            "sheet_count": 0,
                        },
                    }
                }
            ],
        }

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert result["success"] is False
        assert "analysis" in result

    def test_backwards_compatible_with_plain_dict(self):
        """
        Should still handle plain dict (legacy format) for backwards compatibility.

        Ensures we don't break existing behavior if tool returns plain dict.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = {
            "success": True,
            "analysis": {
                "sheets": [{"name": "Legacy", "row_count": 200}],
                "sheet_count": 1,
            },
        }

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "Legacy"

    def test_extracts_from_json_string_toolresult(self):
        """
        Should handle ToolResult format when result is JSON string.

        Some scenarios may serialize the entire ToolResult as a string.
        """
        from swarm.response_utils import _extract_tool_output_from_swarm_result

        mock_agent_result = Mock()
        mock_agent_result.result = json.dumps({
            "status": "success",
            "content": [
                {
                    "json": {
                        "success": True,
                        "analysis": {
                            "sheets": [{"name": "StringParsed", "row_count": 75}],
                            "sheet_count": 1,
                        },
                    }
                }
            ],
        })

        mock_swarm_result = Mock()
        mock_swarm_result.results = {"file_analyst": mock_agent_result}

        result = _extract_tool_output_from_swarm_result(
            mock_swarm_result, agent_name="file_analyst", tool_name="unified_analyze_file"
        )

        assert result is not None
        assert "analysis" in result
        assert result["analysis"]["sheets"][0]["name"] == "StringParsed"
